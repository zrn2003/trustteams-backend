import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import pool from './src/db.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runMigration() {
  try {
    console.log('ðŸš€ Starting database migration...');
    
    // Read the SQL file
    const sqlPath = path.join(__dirname, 'sql', 'add_university_columns.sql');
    const sqlContent = fs.readFileSync(sqlPath, 'utf8');
    
    // Split SQL statements
    const statements = sqlContent
      .split(';')
      .map(stmt => stmt.trim())
      .filter(stmt => stmt.length > 0 && !stmt.startsWith('--'));
    
    console.log(`ðŸ“‹ Found ${statements.length} SQL statements to execute`);
    
    // Execute each statement
    for (let i = 0; i < statements.length; i++) {
      const statement = statements[i];
      if (statement.trim()) {
        console.log(`ðŸ”§ Executing statement ${i + 1}: ${statement.substring(0, 50)}...`);
        
        try {
          await pool.query(statement);
          console.log(`âœ… Statement ${i + 1} executed successfully`);
        } catch (error) {
          if (error.code === 'ER_DUP_FIELDNAME') {
            console.log(`âš ï¸ Column already exists, skipping: ${error.message}`);
          } else {
            console.error(`âŒ Error executing statement ${i + 1}:`, error.message);
            throw error;
          }
        }
      }
    }
    
    console.log('ðŸŽ‰ Migration completed successfully!');
    
    // Show the updated table structure
    console.log('\nðŸ“Š Current users table structure:');
    const [columns] = await pool.query('DESCRIBE users');
    columns.forEach(col => {
      console.log(`  ${col.Field} | ${col.Type} | ${col.Null} | ${col.Key} | ${col.Default} | ${col.Extra}`);
    });
    
  } catch (error) {
    console.error('ðŸ’¥ Migration failed:', error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

runMigration();
